{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries are now imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_SIFT_FEATURES = 800\n",
    "VOCABULARY_SIZE = 128\n",
    "NUMBER_OF_NEIGHBOURS = 15\n",
    "DISTANCE_METRIC = 'braycurtis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We create a SIFT object detector and descriptor.\n",
    "2. Compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together.\n",
    "3. Compute a k-means clustering on the descriptor space\n",
    "4. For each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word.\n",
    "5. We build a k-nn classifier and train it with the train descriptors\n",
    "6. Compute the test descriptors and compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6b6434950446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mima\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mima\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mkpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSIFTdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mTrain_descriptors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "sift_features = [100,250,500,600,700,800,1000,1250,1500]\n",
    "for nosf in sift_features:\n",
    "    print('1')\n",
    "    SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=nosf)\n",
    "    Train_descriptors = []\n",
    "    Train_label_per_descriptor = []\n",
    "    print('2')\n",
    "    for filename,labels in zip(train_images_filenames,train_labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "        Train_descriptors.append(des)\n",
    "        Train_label_per_descriptor.append(labels)\n",
    "    D=np.vstack(Train_descriptors)\n",
    "    print('3')\n",
    "    k = VOCABULARY_SIZE\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    codebook.fit(D)\n",
    "    print('4')\n",
    "    visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "    for i in range(len(Train_descriptors)):\n",
    "        words=codebook.predict(Train_descriptors[i])\n",
    "        visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "    print('5')\n",
    "    knn = KNeighborsClassifier(n_neighbors=NUMBER_OF_NEIGHBOURS,n_jobs=-1,metric=DISTANCE_METRIC)\n",
    "    knn.fit(visual_words, train_labels)\n",
    "    print('6')\n",
    "    visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "    for i in range(len(test_images_filenames)):\n",
    "        filename=test_images_filenames[i]\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "        words=codebook.predict(des)\n",
    "        visual_words_test[i,:]=np.bincount(words,minlength=k)\n",
    "    result.append(100*knn.score(visual_words_test, test_labels))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Results for different number of Sift Features and other fix values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=NUMBER_OF_NEIGHBOURS,n_jobs=-1,metric=DISTANCE_METRIC)\n",
    "knnpca.fit(VWpca, train_labels) \n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=64)\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=NUMBER_OF_NEIGHBOURS,n_jobs=-1,metric=DISTANCE_METRIC)\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
