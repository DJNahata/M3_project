{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M3. Research Fisher Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from utils.CodeTimer import CodeTimer\n",
    "from utils.DatasetManager import DatasetManager\n",
    "from descriptors.SIFT import DenseSIFT\n",
    "from descriptors.VisualWords import VisualWords\n",
    "from utils.Kernels import histogram_intersection_kernel\n",
    "from fishervector import FisherVectorGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetManager('../Databases/MIT_split')\n",
    "train_img_paths, train_labels, test_img_paths, test_labels = dataset.load_dataset()\n",
    "SAVE_PATH = '../SavePath/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 896\n",
    "STEP_SIZE = 16\n",
    "DESC_SIZE = [8,16]\n",
    "K_FOLDS = 5\n",
    "PARAMETERS = {\n",
    "    'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "    'gamma': [\"scale\"],\n",
    "    'kernel': [\"rbf\", \"sigmoid\", histogram_intersection_kernel]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseSIFT = DenseSIFT()\n",
    "train_desc_path = SAVE_PATH + 'desc_fisher' + os.sep + 'train.dat'\n",
    "test_desc_path = SAVE_PATH  + 'desc_fisher' + os.sep + 'test.dat'\n",
    "train_data_path = SAVE_PATH + 'data_fisher' + os.sep + 'train.dat'\n",
    "test_data_path = SAVE_PATH  + 'data_fisher' + os.sep + 'test.dat'\n",
    "\n",
    "train_desc = DenseSIFT.compute(train_img_paths, STEP_SIZE, DESC_SIZE)\n",
    "test_desc = DenseSIFT.compute(test_img_paths, STEP_SIZE, DESC_SIZE)\n",
    "# Save computed data\n",
    "pickle.dump(train_desc, open(train_desc_path, 'wb'))\n",
    "pickle.dump(test_desc, open(test_desc_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example given in the github of fishervector library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 256, 64)\n",
      "fitted GMM with 5 kernels\n",
      "(10, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "shape = [300, 20, 32] # e.g. SIFT image features\n",
    "image_data = np.random.rand(300,256,64)\n",
    "print(image_data.shape)\n",
    "#image_data = np.concatenate([np.random.normal(np.ones(30), size=shape), np.random.normal(np.ones(30), size=shape)], axis=0)\n",
    "from fishervector import FisherVectorGMM\n",
    "fv_gmm_test = FisherVectorGMM(n_kernels=5).fit(image_data)\n",
    "image_data_test = image_data[:10] # use a fraction of the data to compute the fisher vectors\n",
    "fv = fv_gmm_test.predict(image_data_test)\n",
    "print(fv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1881, 512, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_desc).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE = 16\n",
    "DESC_SIZE = [8,16]\n",
    "N_CLUSTERS = 256\n",
    "N_KERNELS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute FisherVectors Gaussian Mixture Model\n",
      "fitted GMM with 15 kernels\n"
     ]
    }
   ],
   "source": [
    "train_desc_path = SAVE_PATH + 'desc_fisher' + os.sep + 'train.dat'\n",
    "test_desc_path = SAVE_PATH  + 'desc_fisher' + os.sep + 'test.dat'\n",
    "train_data_path = SAVE_PATH + 'data_fisher' + os.sep + 'train.dat'\n",
    "test_data_path = SAVE_PATH  + 'data_fisher' + os.sep + 'test.dat'\n",
    "# Check for existing data files already computed\n",
    "train_desc = pickle.load(open(train_desc_path, 'rb'))\n",
    "test_desc = pickle.load(open(test_desc_path, 'rb'))\n",
    "# Obtain Fisher Vectors for train and test sets\n",
    "print(\"Compute FisherVectors Gaussian Mixture Model\")\n",
    "fv_gmm = FisherVectorGMM(n_kernels=N_KERNELS).fit(np.array(train_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_500 = fv_gmm.predict(np.array(train_desc)[:500])\n",
    "train_data_500_1000 = fv_gmm.predict(np.array(train_desc)[500:1000])\n",
    "train_data_1000_1500 = fv_gmm.predict(np.array(train_desc)[1000:1500])\n",
    "train_data_1500_end = fv_gmm.predict(np.array(train_desc)[1500:np.array(train_desc).shape[0]])\n",
    "train_data = np.concatenate((train_data_500, train_data_500_1000, train_data_1000_1500, train_data_1500_end), axis=0)\n",
    "pickle.dump(train_data, open(train_data_path, 'wb'))\n",
    "\n",
    "test_data_500  = fv_gmm.predict(np.array(test_desc)[:500])\n",
    "test_data_500_end  = fv_gmm.predict(np.array(test_desc)[500:np.array(test_desc).shape[0]])\n",
    "test_data = np.concatenate((test_data_500, test_data_500_end), axis=0)\n",
    "pickle.dump(test_data, open(test_data_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "PARAMETERS = {\n",
    "    'C': [1e-1],\n",
    "    'gamma': [\"scale\"],\n",
    "    'kernel': [\"rbf\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   24.0s remaining:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SVM: 46.837796688079834 s\n",
      "Test SVM: 19.98820209503174 s\n",
      "Not Normalized Train accuracy score: 0.34502923976608185\n",
      "Test accuracy score: 0.31226765799256506\n",
      "Best params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "All results: {'mean_fit_time': array([18.73633823]), 'std_fit_time': array([0.1077532]), 'mean_score_time': array([4.05638618]), 'std_score_time': array([0.07759704]), 'param_C': masked_array(data=[0.1],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=['scale'],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=['rbf'],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}], 'split0_test_score': array([0.22691293]), 'split1_test_score': array([0.25329815]), 'split2_test_score': array([0.2393617]), 'split3_test_score': array([0.24266667]), 'split4_test_score': array([0.22849462]), 'mean_test_score': array([0.23817119]), 'std_test_score': array([0.00971979]), 'rank_test_score': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "train_data = pickle.load(open(train_data_path, 'rb'))\n",
    "test_data = pickle.load(open(test_data_path, 'rb'))\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], 30*128)\n",
    "test_data = test_data.reshape(test_data.shape[0], 30*128)\n",
    "\n",
    "with CodeTimer(\"Train SVM\"):\n",
    "    print(\"Train SVM\")\n",
    "    cv = GridSearchCV(SVC(), param_grid=PARAMETERS, cv=K_FOLDS, n_jobs=-1, verbose=5)\n",
    "    cv.fit(train_data, train_labels)\n",
    "\n",
    "# Test SVM\n",
    "with CodeTimer(\"Test SVM\"):\n",
    "    train_score = cv.score(train_data, train_labels)\n",
    "    test_score = cv.score(test_data, test_labels)\n",
    "        \n",
    "print(\"Not Normalized Train accuracy score: {}\\nTest accuracy score: {}\\nBest params: {}\\n\".format(train_score, test_score, cv.best_params_))\n",
    "print(\"All results: {}\".format(cv.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
